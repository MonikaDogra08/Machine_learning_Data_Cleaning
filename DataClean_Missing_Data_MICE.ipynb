{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description : Code for replacing missing data by using MICE algorithm\n",
    "####  Link :(https://www.kaggle.com/rtatman/data-cleaning-challenge-cleaning-numeric-columns/)\n",
    "###### Author : Monika Dogra\n",
    "###### Revision : 1\n",
    "###### Date : 28 Aug 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction : Pandas-MICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project provides an Sklearn type interface for imputing independent variables using MICE (Multiple Imputation by Chained Equations). MICE has become an industry standard way of dealing with null values while preprocessing data. It is argued that by simply using fill values such as the mean or mode we are throwing information away that is present in other variables that might give insight into what the null values might be. With that thought in mind, we predict the null values from the other features present in the data. Thus preserving as much information as possible. If the data is not missing at random (MAR) then this method is inappropriate. Instead use a feature descritization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features:\n",
    "### *The model preserves the users pandas dataframe column and row indexes.\n",
    "    The model can be fit on past data and applied to new unseen data using fit and transform methods separate from one another. This allows for supporting machine learning applications.\n",
    "    Only columns that are never null in the training set are used to fit the model unless the user sets the \"seed_nulls\" argument to \"True\". This then fills all other nulls in the data based on the standard Sklearn Imputer methods. The null target variable is then predicted using this filled data.\n",
    "    A class variable holds the fitted models for each feature in a dictionary that can be accessed through the API. This can be saved and used at a later time if needed.\n",
    " \n",
    "\n",
    "## The chained equation process can be broken down into four general steps:\n",
    "\n",
    "    Step 1: A simple imputation, such as imputing the mean, is performed for every missing value in the dataset. These mean imputations can be thought of as “place holders.”\n",
    "\n",
    "    Step 2: The “place holder” mean imputations for one variable (“var”) are set back to missing.\n",
    "\n",
    "    Step 3: The observed values from the variable “var” in Step 2 are regressed on the other variables in the imputation model, which may or may not consist of all of the variables in the dataset. In other words, “var” is the dependent variable in a regression model and all the other variables are independent variables in the regression model. These regression models operate under the same assumptions that one would make when performing (e.g.,) linear, logistic, or Poison regression models outside of the context of imputing missing data.\n",
    "\n",
    "    Step 4: The missing values for “var” are then replaced with predictions (imputations) from the regression model. When “var” is subsequently used as an independent variable in the regression models for other variables, both the observed and these imputed values will be used.\n",
    "\n",
    "    Step 5: Steps 2–4 are then repeated for each variable that has missing data. The cycling through each of the variables constitutes one iteration or “cycle.” At the end of one cycle all of the missing values have been replaced with predictions from regressions that reflect the relationships observed in the data.\n",
    "\n",
    "    Step 6: Steps 2 through 4 are repeated for a number of cycles, with the imputations being updated at each cycle. The number of cycles to be performed can be specified by the researcher. At the end of these cycles the final imputations are retained, resulting in one imputed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"/home/ritesh/Desktop/md_work/data/Missing_Data.csv\")\n",
    "print(df)\n",
    "df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age   Salary\n",
      "0  44.0  72000.0\n",
      "1  27.0  48000.0\n",
      "2  30.0  54000.0\n",
      "3  38.0  61000.0\n",
      "4  40.0      NaN\n",
      "5  35.0  58000.0\n",
      "6   NaN  52000.0\n",
      "7  48.0  79000.0\n",
      "8  50.0  83000.0\n",
      "9  37.0  67000.0\n"
     ]
    }
   ],
   "source": [
    "# Locations with empty values:\n",
    "df_1 = df.loc[:, [\"Age\",\"Salary\"]]\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country        Age        Salary Purchased\n",
      "0   France  44.000000  72000.000000        No\n",
      "1    Spain  27.000000  48000.000000       Yes\n",
      "2  Germany  30.000000  54000.000000        No\n",
      "3    Spain  38.000000  61000.000000        No\n",
      "4  Germany  40.000000  63777.777778       Yes\n",
      "5   France  35.000000  58000.000000       Yes\n",
      "6    Spain  38.777778  52000.000000        No\n",
      "7   France  48.000000  79000.000000       Yes\n",
      "8  Germany  50.000000  83000.000000        No\n",
      "9   France  37.000000  67000.000000       Yes\n"
     ]
    }
   ],
   "source": [
    "df_1 = df_1.fillna(df_1.mean())         # Filling only mean() values before implementing MICE algorithum.\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age   Salary\n",
      "0  44.0  72000.0\n",
      "1  27.0  48000.0\n",
      "2  30.0  54000.0\n",
      "3  38.0  61000.0\n",
      "4  40.0  83000.0\n",
      "5  35.0  58000.0\n",
      "6  50.0  52000.0\n",
      "7  48.0  79000.0\n",
      "8  50.0  83000.0\n",
      "9  37.0  67000.0\n"
     ]
    }
   ],
   "source": [
    "# MICE is used to impute numeric data only,if the dataset contains categorical data but you wish to impute numeric data you should use just the numeric columns of the dataframe. If categorical data is missing then a different algorithm would have to be used.\n",
    "\n",
    " \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.impute import SimpleImputer \n",
    "class MiceImputer:\n",
    "    \n",
    "    model_dict_ = {}                                       #'MiceImputer' object has attribute:model_dict_ = {}\n",
    "    \n",
    "    def __init__(self, seed_nulls=False, seed_strategy='mean'):\n",
    "        self.seed_nulls = seed_nulls\n",
    "        self.seed_strategy = seed_strategy\n",
    "    \n",
    "\n",
    "    def transform(self, X):                                # Impute all missing values in X.\n",
    "        col_order = X.columns\n",
    "        new_X = []\n",
    "        mutate_cols = list(self.model_dict_.keys())        # Convert dictionary into list of tuples.\n",
    "  \n",
    "        \n",
    "        for i in mutate_cols:\n",
    "            y = X[i]\n",
    "            x_null = X[y.isnull()]                         # ISNULL() function lets you return an boolean value when an expression is NULL.\n",
    "            y_null = y[y.isnull()].reset_index()['index']  # Just reset the index, without inserting it as a column in the new DataFrame\n",
    "            y_notnull = y[y.notnull()]                     # notnull() method which stores True for ever NON-NULL value and False for a null value.\n",
    "            \n",
    "            model = self.model_dict_.get(i)\n",
    "            \n",
    "            if self.seed_nulls:                           # The method seed() sets the integer starting value used in generating random numbers. Call this function before calling any other random module function.\n",
    "                x_null = model[1].transform(x_null)\n",
    "            else:\n",
    "                null_check = x_null.isnull().any()       # Check any value which is null,return boolean values\n",
    "                x_null = x_null[null_check.index[~null_check]]  # Check those columns having no null vales.\n",
    "                \n",
    "# Concatenate pandas objects along a particular axis with optional set logic along the other axes.         \n",
    "            pred = pd.concat([pd.Series(model[0].predict(x_null))\\\n",
    "                              .to_frame()\\\n",
    "                              .set_index(y_null),y_notnull], axis=0)\\\n",
    "                              .rename(columns={0: i})\n",
    "            \n",
    "            new_X.append(pred)\n",
    "\n",
    "        new_X.append(X[X.columns.difference(mutate_cols)])  #The function returns as output a new list of columns from the existing columns excluding the ones given as arguments. \n",
    "        final = pd.concat(new_X, axis=1)[col_order]         # concatenate the columns.\n",
    "\n",
    "        return final\n",
    "        \n",
    "        \n",
    "    def fit(self, X):                                      # Fit the imputer on X.\n",
    "        x = X.fillna(value=np.nan)  \n",
    "\n",
    "        null_check = x.isnull().any()\n",
    "        null_data = x[null_check.index[null_check]]\n",
    "        \n",
    "        for i in null_data:\n",
    "            y = null_data[i]\n",
    "            y_notnull = y[y.notnull()]\n",
    "\n",
    "            model_list = []\n",
    "            if self.seed_nulls:\n",
    "                imp = SimpleImputer(strategy=self.seed_strategy)\n",
    "                model_list.append(imp.fit(x))\n",
    "                non_null_data = pd.DataFrame(imp.fit_transform(x))\n",
    "                \n",
    "            else:\n",
    "                non_null_data = x[null_check.index[~null_check]]\n",
    "                \n",
    "            \n",
    "            x_notnull = non_null_data[y.notnull()]\n",
    "            \n",
    "            if y.nunique() < 2:                                 # nunique() is used to get a count of unique values.\n",
    "                model = LinearRegression()\n",
    "                model.fit(x_notnull, y_notnull)\n",
    "                model_list.insert(0, model)\n",
    "                self.model_dict_.update({i: model_list})\n",
    "            else:\n",
    "                model = LogisticRegression()\n",
    "                model.fit(x_notnull, y_notnull)\n",
    "                model_list.insert(0, model)\n",
    "                self.model_dict_.update({i: model_list})\n",
    "         \n",
    "        return self\n",
    "        \n",
    "\n",
    "    def fit_transform(self, X):                             # Fit to data, then transform it.\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    \n",
    "    \n",
    "customer_df = pd.read_csv(\"/home/ritesh/Desktop/md_work/data/Missing_Data.csv\")  \n",
    "\n",
    "# Create object/instance of class MiceImputer by calling its constructor i.e classname(arguments to init method)\n",
    "\n",
    "miceimputer_obj = MiceImputer(True,\"mean\")\n",
    "\n",
    "print(miceimputer_obj.fit_transform(customer_df.loc[:, [\"Age\",\"Salary\"]]))\n",
    "\n",
    "\n",
    "# Sometimes system may show us Future warning message,so to ignore the warning each time your code is executed, if you wish.\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
